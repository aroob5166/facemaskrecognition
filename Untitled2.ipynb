{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e5111-505d-48bc-868b-edb19f642224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, Dropout, Flatten , Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b846341-c463-4fa4-89cb-10d018d3ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "DIRECTORY = r\"C:\\Users\\aroob\\Desktop\\mask detector\\mask-detector\\dataset\"\n",
    "CATEGORIES = [\"with_mask\",\"without_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809322e1-9cd6-4526-9994-ee3644962678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aroob\\AppData\\Roaming\\Python\\Python37\\site-packages\\PIL\\Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-067a077dda00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\applications\\mobilenet_v2.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'keras.applications.mobilenet_v2.preprocess_input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    114\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     return _preprocess_numpy_input(\n\u001b[1;32m--> 116\u001b[1;33m         x, data_format=data_format, mode=mode)\n\u001b[0m\u001b[0;32m    117\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     return _preprocess_symbolic_input(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36m_preprocess_numpy_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m127.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Loading dataset\n",
    "data = []\n",
    "labels = []\n",
    "CATEGORIES = [\"with_mask\",\"without_mask\"]\n",
    "DIRECTORY = r\"C:\\Users\\aroob\\Desktop\\mask detector\\mask-detector\\dataset\"\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY,category)\n",
    "    for imgName in os.listdir(path):\n",
    "        imgPath = os.path.join(path,imgName)\n",
    "        img = load_img(imgPath,target_size=(224,224))\n",
    "        img = img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        \n",
    "        data.append(img)\n",
    "        labels.append(category)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data,dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72944ac-ef86-4828-b48b-7178f626117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainX,testX,trainY,testY)=train_test_split(data,labels,test_size=0.20,stratify=labels,random_state=42)\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    \n",
    ")\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, Dropout, Flatten , Dense\n",
    "from tensorflow.keras.models import Model\n",
    "baseModel = MobileNetV2(weights = \"imagenet\", include_top = False,input_tensor = Input(shape = (224,224,3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name = \"flatten\")(headModel)\n",
    "headModel = Dense(128,activation = \"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation = \"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs = baseModel.input, outputs = headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72eb1b7-a5d2-4c91-a01f-95a0c6ad9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "opt = Adam(lr = INIT_LR/EPOCHS)\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = opt,metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0683c-ff16-42b9-bb6d-a23462e0cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training model\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainX,testX,trainY,testY)=train_test_split(data,labels,test_size=0.20,stratify=labels,random_state=42)\n",
    "\n",
    "H = model.fit(\n",
    "      aug.flow(trainX,trainY,batch_size=BS),\n",
    "      steps_per_epoch = len(trainX)//BS,\n",
    "      validation_data = (testX,testY),\n",
    "      validation_steps = len(testX)//BS,\n",
    "      epochs = EPOCHS\n",
    "      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055e815-a9fe-47e8-aa67-d8f85b1e9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation model\n",
    "predIdxs = model.predict(testX,batch_size=BS)\n",
    "\n",
    "predIdxs = np.argmax(predIdxs , axis = 1)\n",
    "print(classification_report(testY.argmax(axis=1), predIdx,target_name=lb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b053be-e90c-4dc1-8043-47bcf0733037",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving model\n",
    "\n",
    "model.save(\"mask_detector.model\",save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50da64-5d92-42a0-a262-c10430f9b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting graph\n",
    "N = EPOCHS\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,N),H.history[\"loss\"],label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N),H.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.plot(np.arange(0,N),H.history[\"accuracy\"],label=\"train_acc\")\n",
    "plt.plot(np.arange(0,N),H.history[\"val_accuracy\"],label=\"val_accuracy\")\n",
    "plt.title('Training Loss And Accuracy')\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.savefig('plot.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
